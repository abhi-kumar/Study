## A general definition list (Adopted from Nvidia Research)

1. Artificial Neural Networks - Processing devices that are loosely modelled after the neuronal structure of human brain.

2. Big Data - Describes a large volume of data, bith structured and unstructured, than inundates a business on a day-to-day basis.

3. Convolutional Neural Networks - Comprised of one or more convolutional layers and then followed by one or more fully connected layers in a standard multilayer neural network

4. Deep Learning - Form of machine learning that enables computers to learn from experience and understand the world in terms of heirarchy of conecpts.

5. Embedding - It is a representation of input, or an encoding. 

6. Feedforward Network - Allows signals to travel one way only, from input to output. There are no feedback loops. 

7. Generative adversarial networks - A tyoe of algorithms used in unsupervised machine learning, implemented by a system of two neural networks competing against each other in a zero-sum gamr framework.

8. Highway networks - They are an architecture to let information flow unhindered across several rnn layers on so called information highways.

9. Initialization - Training deep learning models are sufficiently difficult tasks. Most algorithmsare stringly affected by the choice of initialization. The initial point can determine whether the algorithm converges at all, with some initial points being so unstable that the algorithm encounters numerical difficulties and fails together.

10. Jitter - An artificial noise added to the inputs during training, used as another method for regularization and improving generalization of a neural network.

11. K-means algorithms - It is a type of unsupervised learning, which is used when you have unlabeled data. The goal of this algorithm is to find groups in the data, with the number of groups represented by the variable K.

12. Loss function - For each prediction, there in an associated number which is the loss. For a true prediction, the loss will be small and for a totally wrong prediction it will be high.

13. Multi-layer perceptron - It is a feedforward neural network with mulitple fully connected layers that use non-linear activation functions to deal with the data which is not linearly separable. 

14. Natural language processing - It is the comprehension by computers of the structure and meaning of human language, allowing users to interact with the computer using natural sentenses.

15. One-shot learning - It is when an algorithm learns from one or a few number of training examples, contrast to traditional machine learning models which use thousands of such examples.

16. Pooling - Type of layer commonly founds in CNNs, which integrates information from neurons with nearby receptive fields.

17. Q-Networks - A novel artifact agent, termed a deep Q-Network, that can learn succesful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning.

18. Reinforcement learning - A branch of machine learning that is goal oriented, i.e., it's algorithms have as their objective to maximize a reward, often over the course of many decisions. 

19. Variational encoder - It is a directed model that uses learned approximate inference and can be trained purely with gradient based methods.

20. Zer-shot learning - An extreme form of transfer learning, where no labeled examples are given at all. 






## List of terms that appear in this tutorial

### Note: The terms are discussed in details in either of the tutorial folders. Here, their quick definitions are present.


1. Regression - a measure of the relation between the mean value of one variable (e.g. output) and corresponding values of other variables (e.g. time and cost).

2. Multi-collinearity - a state of very high intercorrelations or inter-associations among the independent variables. 

3. Autocorrelation - also known as serial correlation, is the correlation of a signal with a delayed copy of itself as a function of delay. Informally, it is the similarity between observations as a function of the time lag between them. It is a mathematical representation of the degree of similarity between a given time series and a lagged version of itself over successive time intervals

4. Precision - It measures how accurate is your predictions. i.e. the percentage of your positive predictions are correct.

5. Recall - It measures how good you find all the positives. For example, we can find 80% of the possible positive cases in our top K predictions. It answers what proportion of actual positives was identified correctly?

6. mAP - Mean Average Precision. mAP is the metric to measure the accuracy of object detectors.



